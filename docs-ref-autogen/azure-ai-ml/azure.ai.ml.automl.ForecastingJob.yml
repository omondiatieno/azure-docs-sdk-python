### YamlMime:PythonClass
uid: azure.ai.ml.automl.ForecastingJob
name: ForecastingJob
fullName: azure.ai.ml.automl.ForecastingJob
module: azure.ai.ml.automl
inheritances:
- azure.ai.ml.entities._job.automl.tabular.automl_tabular.AutoMLTabular
summary: 'Configuration for AutoML Forecasting Task.


  Initialize a new AutoML Forecasting task.'
constructor:
  syntax: 'ForecastingJob(*, primary_metric: str | None = None, forecasting_settings:
    ForecastingSettings | None = None, **kwargs)'
  parameters:
  - name: primary_metric
    description: The primary metric to use for optimization
    isRequired: true
    types:
    - <xref:str>, <xref:optional>
  - name: forecasting_settings
    description: The settings for the forecasting task
    isRequired: true
    types:
    - <xref:azure.ai.ml.automl.ForecastingSettings>, <xref:optional>
  - name: kwargs
    description: Job-specific arguments
    isRequired: true
    types:
    - <xref:dict>
methods:
- uid: azure.ai.ml.automl.ForecastingJob.dump
  name: dump
  summary: Dump the job content into a file in yaml format.
  signature: 'dump(dest: str | PathLike | IO, **kwargs) -> None'
  parameters:
  - name: dest
    description: 'The destination to receive this job''s content.

      Must be either a path to a local file, or an already-open file stream.

      If dest is a file path, a new file will be created,

      and an exception is raised if the file exists.

      If dest is an open file, the file will be written to directly,

      and an exception will be raised if the file is not writable.'
    isRequired: true
    types:
    - <xref:Union>[<xref:PathLike>, <xref:str>, <xref:IO>[<xref:AnyStr>]]
- uid: azure.ai.ml.automl.ForecastingJob.set_data
  name: set_data
  summary: Define data configuration.
  signature: 'set_data(*, training_data: Input, target_column_name: str, weight_column_name:
    str | None = None, validation_data: Input | None = None, validation_data_size:
    float | None = None, n_cross_validations: str | int | None = None, cv_split_column_names:
    List[str] | None = None, test_data: Input | None = None, test_data_size: float
    | None = None) -> None'
  parameters:
  - name: training_data
    description: Training data.
    types:
    - <xref:azure.ai.ml.Input>
  - name: target_column_name
    description: Column name of the target column.
    types:
    - <xref:str>
  - name: weight_column_name
    description: Weight column name, defaults to None
    types:
    - <xref:typing.Optional>[<xref:str>]
  - name: validation_data
    description: Validation data, defaults to None
    types:
    - <xref:typing.Optional>[<xref:azure.ai.ml.Input>]
  - name: validation_data_size
    description: Validation data size, defaults to None
    types:
    - <xref:typing.Optional>[<xref:float>]
  - name: n_cross_validations
    description: n_cross_validations, defaults to None
    types:
    - <xref:typing.Optional>[<xref:typing.Union>[<xref:str>, <xref:int>]]
  - name: cv_split_column_names
    description: cv_split_column_names, defaults to None
    types:
    - <xref:typing.Optional>[<xref:typing.List>[<xref:str>]]
  - name: test_data
    description: Test data, defaults to None
    types:
    - <xref:typing.Optional>[<xref:azure.ai.ml.Input>]
  - name: test_data_size
    description: Test data size, defaults to None
    types:
    - <xref:typing.Optional>[<xref:float>]
- uid: azure.ai.ml.automl.ForecastingJob.set_featurization
  name: set_featurization
  summary: Define feature engineering configuration.
  signature: 'set_featurization(*, blocked_transformers: List[BlockedTransformers
    | str] | None = None, column_name_and_types: Dict[str, str] | None = None, dataset_language:
    str | None = None, transformer_params: Dict[str, List[ColumnTransformer]] | None
    = None, mode: str | None = None, enable_dnn_featurization: bool | None = None)
    -> None'
  parameters:
  - name: blocked_transformers
    description: A list of transformer names to be blocked during featurization, defaults
      to None
    types:
    - <xref:Optional>[<xref:List>[<xref:Union>[<xref:azure.ai.ml.automl.BlockedTransformers>,
      <xref:str>]]]
  - name: column_name_and_types
    description: 'A dictionary of column names and feature types used to update column
      purpose

      , defaults to None'
    types:
    - <xref:Optional>[<xref:Dict>[<xref:str>, <xref:str>]]
  - name: dataset_language
    description: 'Three character ISO 639-3 code for the language(s) contained in
      the dataset.

      Languages other than English are only supported if you use GPU-enabled compute.  The
      language_code

      ''mul'' should be used if the dataset contains multiple languages. To find ISO
      639-3 codes for different

      languages, please refer to [https://en.wikipedia.org/wiki/List_of_ISO_639-3_codes](https://en.wikipedia.org/wiki/List_of_ISO_639-3_codes),
      defaults to None'
    types:
    - <xref:Optional>[<xref:str>]
  - name: transformer_params
    description: 'A dictionary of transformer and corresponding customization parameters

      , defaults to None'
    types:
    - <xref:Optional>[<xref:Dict>[<xref:str>, <xref:List>[<xref:azure.ai.ml.automl.ColumnTransformer>]]]
  - name: mode
    description: '"off", "auto", defaults to "auto", defaults to None'
    types:
    - <xref:Optional>[<xref:str>]
  - name: enable_dnn_featurization
    description: Whether to include DNN based feature engineering methods, defaults
      to None
    types:
    - <xref:Optional>[<xref:bool>]
- uid: azure.ai.ml.automl.ForecastingJob.set_forecast_settings
  name: set_forecast_settings
  summary: Manage parameters used by forecasting tasks.
  signature: 'set_forecast_settings(*, time_column_name: str | None = None, forecast_horizon:
    str | int | None = None, time_series_id_column_names: str | List[str] | None =
    None, target_lags: str | int | List[int] | None = None, feature_lags: str | None
    = None, target_rolling_window_size: str | int | None = None, country_or_region_for_holidays:
    str | None = None, use_stl: str | None = None, seasonality: str | int | None =
    None, short_series_handling_config: str | None = None, frequency: str | None =
    None, target_aggregate_function: str | None = None, cv_step_size: int | None =
    None) -> None'
  parameters:
  - name: time_column_name
    description: 'The name of the time column. This parameter is required when forecasting
      to specify the datetime

      column in the input data used for building the time series and inferring its
      frequency.'
    isRequired: true
    types:
    - <xref:str>
  - name: forecast_horizon
    description: 'The desired maximum forecast horizon in units of time-series frequency.
      The default value is 1.


      Units are based on the time interval of your training data, e.g., monthly, weekly
      that the forecaster

      should predict out. When task type is forecasting, this parameter is required.
      For more information on

      setting forecasting parameters, see [Auto-train a time-series forecast model](https://docs.microsoft.com/azure/machine-learning/how-to-auto-train-forecast).'
    isRequired: true
    types:
    - <xref:int>
    - <xref:str>
  - name: time_series_id_column_names
    description: 'The names of columns used to group a timeseries.

      It can be used to create multiple series. If time series id column names is
      not defined or

      the identifier columns specified do not identify all the series in the dataset,
      the time series identifiers

      will be automatically created for your dataset.'
    isRequired: true
    types:
    - <xref:str>
    - <xref:list>(<xref:str>)
  - name: target_lags
    description: "The number of past periods to lag from the target column. By default\
      \ the lags are turned off.\n\nWhen forecasting, this parameter represents the\
      \ number of rows to lag the target values based\non the frequency of the data.\
      \ This is represented as a list or single integer. Lag should be used\nwhen\
      \ the relationship between the independent variables and dependent variable\
      \ do not match up or\ncorrelate by default. For example, when trying to forecast\
      \ demand for a product, the demand in any\nmonth may depend on the price of\
      \ specific commodities 3 months prior. In this example, you may want\nto lag\
      \ the target (demand) negatively by 3 months so that the model is training on\
      \ the correct\nrelationship. For more information, see [Auto-train a time-series\
      \ forecast model](https://docs.microsoft.com/azure/machine-learning/how-to-auto-train-forecast).\n\
      \n**Note on auto detection of target lags and rolling window size.\nPlease see\
      \ the corresponding comments in the rolling window section.**\nWe use the next\
      \ algorithm to detect the optimal target lag and rolling window size.\n\n1.\
      \ Estimate the maximum lag order for the look back feature selection. In our\
      \ case it is the number of periods till the next date frequency granularity\
      \ i.e. if frequency is daily, it will be a week (7), if it is a week, it will\
      \ be month (4). That values multiplied by two is the largest possible values\
      \ of lags/rolling windows. In our examples, we will consider the maximum lag\
      \ order of 14 and 8 respectively). \n\n2. Create a de-seasonalized series by\
      \ adding trend and residual components. This will be used in the next step.\
      \ \n\n3. Estimate the PACF - Partial Auto Correlation Function on the on the\
      \ data from (2) and search for points, where the auto correlation is significant\
      \ i.e. its absolute value is more then 1.96/square_root(maximal lag value),\
      \ which correspond to significance of 95%. \n\n4. If all points are significant,\
      \ we consider it being strong seasonality and do not create look back features.\
      \ \n\n5. We scan the PACF values from the beginning and the value before the\
      \ first insignificant auto correlation will designate the lag. If first significant\
      \ element (value correlate with itself) is followed by insignificant, the lag\
      \ will be 0 and we will not use look back features."
    isRequired: true
    types:
    - <xref:int>, <xref:str,>
    - <xref:list>(<xref:int>)
  - name: feature_lags
    description: Flag for generating lags for the numeric features with 'auto' or
      None.
    isRequired: true
    types:
    - <xref:str>
    - <xref:None>
  - name: target_rolling_window_size
    description: 'The number of past periods used to create a rolling window average
      of the target column.


      When forecasting, this parameter represents *n* historical periods to use to
      generate forecasted values,

      <= training set size. If omitted, *n* is the full training set size. Specify
      this parameter

      when you only want to consider a certain amount of history when training the
      model.

      If set to ''auto'', rolling window will be estimated as the last

      value where the PACF is more then the significance threshold. Please see target_lags
      section for details.'
    isRequired: true
    types:
    - <xref:int>, <xref:str>
    - <xref:None>
  - name: country_or_region_for_holidays
    description: 'The country/region used to generate holiday features.

      These should be ISO 3166 two-letter country/region codes, for example ''US''
      or ''GB''.'
    isRequired: true
    types:
    - <xref:str>
    - <xref:None>
  - name: use_stl
    description: 'Configure STL Decomposition of the time-series target column.

      use_stl can take three values: None (default) - no stl decomposition, ''season''
      - only generate

      season component and season_trend - generate both season and trend components.'
    isRequired: true
    types:
    - <xref:str>
    - <xref:None>
  - name: seasonality
    description: 'Set time series seasonality as an integer multiple of the series
      frequency.

      If seasonality is set to ''auto'', it will be inferred.

      If set to None, the time series is assumed non-seasonal which is equivalent
      to seasonality=1.'
    isRequired: true
    types:
    - <xref:int>, <xref:str>
    - <xref:None>
  - name: short_series_handling_config
    description: 'The parameter defining how if AutoML should handle short time series.


      Possible values: ''auto'' (default), ''pad'', ''drop'' and None.

      * **auto** short series will be padded if there are no long series,

      otherwise short series will be dropped.

      * **pad** all the short series will be padded.

      * **drop**  all the short series will be dropped".

      * **None** the short series will not be modified.

      If set to ''pad'', the table will be padded with the zeroes and

      empty values for the regressors and random values for target with the mean

      equal to target value median for given time series id. If median is more or
      equal

      to zero, the minimal padded value will be clipped by zero:

      Input:


      :::row:::

      :::column:::

      **Date**

      :::column-end:::

      :::column:::

      **numeric_value**

      :::column-end:::

      :::column:::

      **string**

      :::column-end:::

      :::column:::

      **target**

      :::column-end:::

      :::row-end:::

      :::row:::

      :::column:::

      2020-01-01

      :::column-end:::

      :::column:::

      23

      :::column-end:::

      :::column:::

      green

      :::column-end:::

      :::column:::

      55

      :::column-end:::

      :::row-end:::


      Output assuming minimal number of values is four:


      :::row:::

      :::column:::

      **Date**

      :::column-end:::

      :::column:::

      **numeric_value**

      :::column-end:::

      :::column:::

      **string**

      :::column-end:::

      :::column:::

      **target**

      :::column-end:::

      :::row-end:::

      :::row:::

      :::column:::

      2019-12-29

      :::column-end:::

      :::column:::

      0

      :::column-end:::

      :::column:::

      NA

      :::column-end:::

      :::column:::

      55.1

      :::column-end:::

      :::row-end:::

      :::row:::

      :::column:::

      2019-12-30

      :::column-end:::

      :::column:::

      0

      :::column-end:::

      :::column:::

      NA

      :::column-end:::

      :::column:::

      55.6

      :::column-end:::

      :::row-end:::

      :::row:::

      :::column:::

      2019-12-31

      :::column-end:::

      :::column:::

      0

      :::column-end:::

      :::column:::

      NA

      :::column-end:::

      :::column:::

      54.5

      :::column-end:::

      :::row-end:::

      :::row:::

      :::column:::

      2020-01-01

      :::column-end:::

      :::column:::

      23

      :::column-end:::

      :::column:::

      green

      :::column-end:::

      :::column:::

      55

      :::column-end:::

      :::row-end:::


      **Note:** We have two parameters short_series_handling_configuration and

      legacy short_series_handling. When both parameters are set we are

      synchronize them as shown in the table below (short_series_handling_configuration
      and

      short_series_handling for brevity are marked as handling_configuration and handling

      respectively).


      :::row:::

      :::column:::

      **handling**

      :::column-end:::

      :::column:::

      **handling_configuration**

      :::column-end:::

      :::column:::

      **resulting handling**

      :::column-end:::

      :::column:::

      **resulting handling_configuration**

      :::column-end:::

      :::row-end:::

      :::row:::

      :::column:::

      True

      :::column-end:::

      :::column:::

      auto

      :::column-end:::

      :::column:::

      True

      :::column-end:::

      :::column:::

      auto

      :::column-end:::

      :::row-end:::

      :::row:::

      :::column:::

      True

      :::column-end:::

      :::column:::

      pad

      :::column-end:::

      :::column:::

      True

      :::column-end:::

      :::column:::

      auto

      :::column-end:::

      :::row-end:::

      :::row:::

      :::column:::

      True

      :::column-end:::

      :::column:::

      drop

      :::column-end:::

      :::column:::

      True

      :::column-end:::

      :::column:::

      auto

      :::column-end:::

      :::row-end:::

      :::row:::

      :::column:::

      True

      :::column-end:::

      :::column:::

      None

      :::column-end:::

      :::column:::

      False

      :::column-end:::

      :::column:::

      None

      :::column-end:::

      :::row-end:::

      :::row:::

      :::column:::

      False

      :::column-end:::

      :::column:::

      auto

      :::column-end:::

      :::column:::

      False

      :::column-end:::

      :::column:::

      None

      :::column-end:::

      :::row-end:::

      :::row:::

      :::column:::

      False

      :::column-end:::

      :::column:::

      pad

      :::column-end:::

      :::column:::

      False

      :::column-end:::

      :::column:::

      None

      :::column-end:::

      :::row-end:::

      :::row:::

      :::column:::

      False

      :::column-end:::

      :::column:::

      drop

      :::column-end:::

      :::column:::

      False

      :::column-end:::

      :::column:::

      None

      :::column-end:::

      :::row-end:::

      :::row:::

      :::column:::

      False

      :::column-end:::

      :::column:::

      None

      :::column-end:::

      :::column:::

      False

      :::column-end:::

      :::column:::

      None

      :::column-end:::

      :::row-end:::'
    isRequired: true
    types:
    - <xref:str>
    - <xref:None>
  - name: frequency
    description: 'Forecast frequency.


      When forecasting, this parameter represents the period with which the forecast
      is desired,

      for example daily, weekly, yearly, etc. The forecast frequency is dataset frequency
      by default.

      You can optionally set it to greater (but not lesser) than dataset frequency.

      We''ll aggregate the data and generate the results at forecast frequency. For
      example,

      for daily data, you can set the frequency to be daily, weekly or monthly, but
      not hourly.

      The frequency needs to be a pandas offset alias.

      Please refer to pandas documentation for more information:

      [https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects)'
    isRequired: true
    types:
    - <xref:str>
    - <xref:None>
  - name: target_aggregate_function
    description: "The function to be used to aggregate the time series target\n  \
      \ column to conform to a user specified frequency. If the\n   target_aggregation_function\
      \ is set, but the freq parameter\n   is not set, the error is raised. The possible\
      \ target\n   aggregation functions are: \"sum\", \"max\", \"min\" and \"mean\"\
      .\n\n* The target column values are aggregated based on the specified operation.\
      \ Typically, sum is appropriate for most scenarios. \n\n* Numerical predictor\
      \ columns in your data are aggregated by sum, mean, minimum value, and maximum\
      \ value. As a result, automated ML generates new columns suffixed with the aggregation\
      \ function name and applies the selected aggregate operation. \n\n* For categorical\
      \ predictor columns, the data is aggregated by mode, the most prominent category\
      \ in the window. \n\n* Date predictor columns are aggregated by minimum value,\
      \ maximum value and mode. \n\n:::row:::\n:::column:::\n**freq**\n:::column-end:::\n\
      :::column:::\n**target_aggregation_function**\n:::column-end:::\n:::column:::\n\
      **Data regularity fixing mechanism**\n:::column-end:::\n:::row-end:::\n:::row:::\n\
      :::column:::\nNone (Default)\n:::column-end:::\n:::column:::\nNone (Default)\n\
      :::column-end:::\n:::column:::\nThe aggregation is not applied.If the valid\
      \ frequency can not bedetermined the error will be raised.\n:::column-end:::\n\
      :::row-end:::\n:::row:::\n:::column:::\nSome Value\n:::column-end:::\n:::column:::\n\
      None (Default)\n:::column-end:::\n:::column:::\nThe aggregation is not applied.If\
      \ the number of data points compliantto given frequency grid is less then 90%these\
      \ points will be removed, otherwisethe error will be raised.\n:::column-end:::\n\
      :::row-end:::\n:::row:::\n:::column:::\nNone (Default)\n:::column-end:::\n:::column:::\n\
      Aggregation function\n:::column-end:::\n:::column:::\nThe error about missing\
      \ frequency parameteris raised.\n:::column-end:::\n:::row-end:::\n:::row:::\n\
      :::column:::\nSome Value\n:::column-end:::\n:::column:::\nAggregation function\n\
      :::column-end:::\n:::column:::\nAggregate to frequency using providedaggregation\
      \ function.\n:::column-end:::\n:::row-end:::"
    isRequired: true
    types:
    - <xref:str>
    - <xref:None>
  - name: cv_step_size
    description: 'Number of periods between the origin_time of one CV fold and the
      next fold. For

      example, if *n_step* = 3 for daily data, the origin time for each fold will
      be

      three days apart.'
    isRequired: true
    types:
    - <xref:int>
    - <xref:None>
- uid: azure.ai.ml.automl.ForecastingJob.set_limits
  name: set_limits
  summary: Set limits for the job.
  signature: 'set_limits(*, enable_early_termination: bool | None = None, exit_score:
    float | None = None, max_concurrent_trials: int | None = None, max_cores_per_trial:
    int | None = None, max_nodes: int | None = None, max_trials: int | None = None,
    timeout_minutes: int | None = None, trial_timeout_minutes: int | None = None)
    -> None'
  parameters:
  - name: enable_early_termination
    description: "Whether to enable early termination if the score is not improving\
      \ in the\nshort term, defaults to None.\n\nEarly stopping logic:\n\n* No early\
      \ stopping for first 20 iterations (landmarks). \n\n* Early stopping window\
      \ starts on the 21st iteration and looks for early_stopping_n_iters iterations\n\
      \n     (currently set to 10). This means that the first iteration where stopping\
      \ can occur is the 31st.\n\n* AutoML still schedules 2 ensemble iterations AFTER\
      \ early stopping, which might result in higher scores. \n\n* Early stopping\
      \ is triggered if the absolute value of best score calculated is the same for\
      \ past\n\n     early_stopping_n_iters iterations, that is, if there is no improvement\
      \ in score for\n     early_stopping_n_iters iterations."
    types:
    - <xref:typing.Optional>[<xref:bool>]
  - name: exit_score
    description: 'Target score for experiment. The experiment terminates after this
      score is reached.

      If not specified (no criteria), the experiment runs until no further progress
      is made

      on the primary metric. For for more information on exit criteria, see this [article](https://docs.microsoft.com/azure/machine-learning/how-to-configure-auto-train#exit-criteria)

      , defaults to None'
    types:
    - <xref:typing.Optional>[<xref:float>]
  - name: max_concurrent_trials
    description: "This is the maximum number of iterations that would be executed\
      \ in parallel.\nThe default value is 1.\n\n* AmlCompute clusters support one\
      \ iteration running per node. \n\nFor multiple AutoML experiment parent runs\
      \ executed in parallel on a single AmlCompute cluster, the\nsum of the `max_concurrent_trials`\
      \ values for all experiments should be less\nthan or equal to the maximum number\
      \ of nodes. Otherwise, runs will be queued until nodes are available.\n\n* DSVM\
      \ supports multiple iterations per node. `max_concurrent_trials` should \n\n\
      be less than or equal to the number of cores on the DSVM. For multiple experiments\n\
      run in parallel on a single DSVM, the sum of the `max_concurrent_trials` values\
      \ for all\nexperiments should be less than or equal to the maximum number of\
      \ nodes.\n\n* Databricks - `max_concurrent_trials` should be less than or equal\
      \ to the number of \n\nworker nodes on Databricks.\n\n`max_concurrent_trials`\
      \ does not apply to local runs. Formerly, this parameter\nwas named `concurrent_iterations`."
    types:
    - <xref:typing.Optional>[<xref:int>]
  - name: max_cores_per_trial
    description: "The maximum number of threads to use for a given training iteration.\n\
      Acceptable values:\n\n* Greater than 1 and less than or equal to the maximum\
      \ number of cores on the compute target. \n\n* Equal to -1, which means to use\
      \ all the possible cores per iteration per child-run. \n\n* Equal to 1, the\
      \ default."
    types:
    - <xref:typing.Optional>[<xref:int>]
  - name: max_nodes
    description: "[Experimental] The maximum number of nodes to use for distributed\
      \ training.\n\n* For forecasting, each model is trained using max(2, int(max_nodes\
      \ / max_concurrent_trials)) nodes. \n\n* For classification/regression, each\
      \ model is trained using max_nodes nodes. \n\nNote- This parameter is in public\
      \ preview and might change in future."
    types:
    - <xref:typing.Optional>[<xref:int>]
  - name: max_trials
    description: 'The total number of different algorithm and parameter combinations
      to test during an

      automated ML experiment. If not specified, the default is 1000 iterations.'
    types:
    - <xref:typing.Optional>[<xref:int>]
  - name: timeout_minutes
    description: 'Maximum amount of time in minutes that all iterations combined can
      take before the

      experiment terminates. If not specified, the default experiment timeout is 6
      days. To specify a timeout

      less than or equal to 1 hour, make sure your dataset''s size is not greater
      than

      10,000,000 (rows times column) or an error results, defaults to None'
    types:
    - <xref:typing.Optional>[<xref:int>]
  - name: trial_timeout_minutes
    description: 'Maximum time in minutes that each iteration can run for before it
      terminates.

      If not specified, a value of 1 month or 43200 minutes is used, defaults to None'
    types:
    - <xref:typing.Optional>[<xref:int>]
- uid: azure.ai.ml.automl.ForecastingJob.set_training
  name: set_training
  signature: 'set_training(*, enable_onnx_compatible_models: bool | None = None, enable_dnn_training:
    bool | None = None, enable_model_explainability: bool | None = None, enable_stack_ensemble:
    bool | None = None, enable_vote_ensemble: bool | None = None, stack_ensemble_settings:
    StackEnsembleSettings | None = None, ensemble_model_download_timeout: int | None
    = None, allowed_training_algorithms: List[str] | None = None, blocked_training_algorithms:
    List[str] | None = None, training_mode: str | TrainingMode | None = None) -> None'
attributes:
- uid: azure.ai.ml.automl.ForecastingJob.base_path
  name: base_path
  summary: Base path of the resource.
  return:
    description: Base path of the resource
    types:
    - <xref:str>
- uid: azure.ai.ml.automl.ForecastingJob.creation_context
  name: creation_context
  summary: Creation context.
  return:
    description: Creation metadata of the resource.
    types:
    - <xref:typing.Optional>[<xref:azure.ai.ml.entities.SystemData>]
- uid: azure.ai.ml.automl.ForecastingJob.featurization
  name: featurization
  summary: Get the tabular featurization settings for the AutoML job.
  return:
    description: Tabular featurization settings for the AutoML job
    types:
    - <xref:azure.ai.ml.automl.TabularFeaturizationSettings>
- uid: azure.ai.ml.automl.ForecastingJob.forecasting_settings
  name: forecasting_settings
- uid: azure.ai.ml.automl.ForecastingJob.id
  name: id
  summary: Resource ID.
  return:
    description: Global id of the resource, Azure Resource Manager ID
    types:
    - <xref:typing.Optional>[<xref:str>]
- uid: azure.ai.ml.automl.ForecastingJob.inputs
  name: inputs
- uid: azure.ai.ml.automl.ForecastingJob.limits
  name: limits
  summary: Get the tabular limits for the AutoML job.
  return:
    description: Tabular limits for the AutoML job
    types:
    - <xref:azure.ai.ml.automl.TabularLimitSettings>
- uid: azure.ai.ml.automl.ForecastingJob.log_files
  name: log_files
  summary: Job output files.
  return:
    description: Dictionary of log names to url.
    types:
    - <xref:Optional>[<xref:Dict>[<xref:str>, <xref:str>]]
- uid: azure.ai.ml.automl.ForecastingJob.log_verbosity
  name: log_verbosity
  summary: Get the log verbosity for the AutoML job.
  return:
    description: log verbosity for the AutoML job
    types:
    - <xref:LogVerbosity>
- uid: azure.ai.ml.automl.ForecastingJob.outputs
  name: outputs
- uid: azure.ai.ml.automl.ForecastingJob.primary_metric
  name: primary_metric
- uid: azure.ai.ml.automl.ForecastingJob.status
  name: status
  summary: "Status of the job.\n\nCommon values returned include \"Running\", \"Completed\"\
    , and \"Failed\".\n\n> [!NOTE]\n> NotStarted - This is a temporary state client-side\
    \ Run objects are in before cloud submission.\n>\n> \n>\n> Starting - The Run\
    \ has started being processed in the cloud. The caller has a run ID at this point.\n\
    >\n> \n>\n> Provisioning - Returned when on-demand compute is being created for\
    \ a given job submission.\n>\n> \n>\n> Preparing - The run environment is being\
    \ prepared:\n>\n> \n>\n> docker image build\n>\n> \n>\n> conda environment setup\n\
    >\n> \n>\n> Queued - The job is queued in the compute target. For example, in\
    \ BatchAI the job is in queued state\n>\n> \n>\n> while waiting for all the requested\
    \ nodes to be ready.\n>\n> \n>\n> Running - The job started to run in the compute\
    \ target.\n>\n> \n>\n> Finalizing - User code has completed and the run is in\
    \ post-processing stages.\n>\n> \n>\n> CancelRequested - Cancellation has been\
    \ requested for the job.\n>\n> \n>\n> Completed - The run completed successfully.\
    \ This includes both the user code and run\n>\n> \n>\n> post-processing stages.\n\
    >\n> \n>\n> Failed - The run failed. Usually the Error property on a run will\
    \ provide details as to why.\n>\n> \n>\n> Canceled - Follows a cancellation request\
    \ and indicates that the run is now successfully cancelled.\n>\n> \n>\n> NotResponding\
    \ - For runs that have Heartbeats enabled, no heartbeat has been recently sent.\n\
    >"
  return:
    description: Status of the job.
    types:
    - <xref:str>
- uid: azure.ai.ml.automl.ForecastingJob.studio_url
  name: studio_url
  summary: Azure ML studio endpoint.
  return:
    description: URL to the job detail page.
    types:
    - <xref:Optional>[<xref:str>]
- uid: azure.ai.ml.automl.ForecastingJob.task_type
  name: task_type
  summary: Get task type.
  return:
    description: 'The type of task to run. Possible values include: "classification",
      "regression", "forecasting".'
    types:
    - <xref:str>
- uid: azure.ai.ml.automl.ForecastingJob.test_data
  name: test_data
  summary: Get test data.
  return:
    description: Test data input
    types:
    - <xref:azure.ai.ml.Input>
- uid: azure.ai.ml.automl.ForecastingJob.training
  name: training
- uid: azure.ai.ml.automl.ForecastingJob.training_data
  name: training_data
  summary: Get training data.
  return:
    description: Training data input
    types:
    - <xref:azure.ai.ml.Input>
- uid: azure.ai.ml.automl.ForecastingJob.type
  name: type
  summary: Type of the job, supported are 'command' and 'sweep'.
  return:
    description: Type of the job.
    types:
    - <xref:str>
- uid: azure.ai.ml.automl.ForecastingJob.validation_data
  name: validation_data
  summary: Get validation data.
  return:
    description: Validation data input
    types:
    - <xref:azure.ai.ml.Input>
