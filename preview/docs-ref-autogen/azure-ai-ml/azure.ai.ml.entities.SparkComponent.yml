### YamlMime:PythonClass
uid: azure.ai.ml.entities.SparkComponent
name: SparkComponent
fullName: azure.ai.ml.entities.SparkComponent
module: azure.ai.ml.entities
inheritances:
- azure.ai.ml.entities._component.component.Component
- azure.ai.ml.entities._job.parameterized_spark.ParameterizedSpark
- azure.ai.ml.entities._job.spark_job_entry_mixin.SparkJobEntryMixin
summary: Spark component version, used to define a spark component.
constructor:
  syntax: 'SparkComponent(*, code: str | PathLike = ''.'', entry: Dict[str, str] |
    SparkJobEntry | None = None, py_files: List[str] | None = None, jars: List[str]
    | None = None, files: List[str] | None = None, archives: List[str] | None = None,
    driver_cores: int = None, driver_memory: str = None, executor_cores: int = None,
    executor_memory: str = None, executor_instances: int = None, dynamic_allocation_enabled:
    bool = None, dynamic_allocation_min_executors: int = None, dynamic_allocation_max_executors:
    int = None, conf: Dict[str, str] | None = None, environment: str | Environment
    = None, inputs: Dict = None, outputs: Dict = None, args: str = None, **kwargs)'
  parameters:
  - name: code
    description: The source code to run the job.
    isRequired: true
    types:
    - <xref:Union>[<xref:str>, <xref:os.PathLike>]
  - name: entry
    description: File or class entry point.
    isRequired: true
    types:
    - <xref:dict>[<xref:str>, <xref:str>]
  - name: py_files
    description: List of .zip, .egg or .py files to place on the PYTHONPATH for Python
      apps.
    isRequired: true
    types:
    - <xref:Optional>[<xref:typing.List>[<xref:str>]]
  - name: jars
    description: List of jars to include on the driver and executor classpaths.
    isRequired: true
    types:
    - <xref:Optional>[<xref:typing.List>[<xref:str>]]
  - name: files
    description: List of files to be placed in the working directory of each executor.
    isRequired: true
    types:
    - <xref:Optional>[<xref:typing.List>[<xref:str>]]
  - name: archives
    description: List of archives to be extracted into the working directory of each
      executor.
    isRequired: true
    types:
    - <xref:Optional>[<xref:typing.List>[<xref:str>]]
  - name: driver_cores
    description: Number of cores to use for the driver process, only in cluster mode.
    isRequired: true
    types:
    - <xref:int>
  - name: driver_memory
    description: Amount of memory to use for the driver process.
    isRequired: true
    types:
    - <xref:str>
  - name: executor_cores
    description: The number of cores to use on each executor.
    isRequired: true
    types:
    - <xref:int>
  - name: executor_memory
    description: 'Amount of memory to use per executor process, in the same format
      as JVM memory strings with

      a size unit suffix ("k", "m", "g" or "t") (e.g. 512m, 2g).'
    isRequired: true
    types:
    - <xref:str>
  - name: executor_instances
    description: Initial number of executors.
    isRequired: true
    types:
    - <xref:int>
  - name: dynamic_allocation_enabled
    description: 'Whether to use dynamic resource allocation, which scales the number
      of executors

      registered with this application up and down based on the workload.'
    isRequired: true
    types:
    - <xref:bool>
  - name: dynamic_allocation_min_executors
    description: Lower bound for the number of executors if dynamic allocation is
      enabled.
    isRequired: true
    types:
    - <xref:int>
  - name: dynamic_allocation_max_executors
    description: Upper bound for the number of executors if dynamic allocation is
      enabled.
    isRequired: true
    types:
    - <xref:int>
  - name: conf
    description: A dict with pre-defined spark configurations key and values.
    isRequired: true
    types:
    - <xref:dict>
  - name: environment
    description: Azure ML environment to run the job in.
    isRequired: true
    types:
    - <xref:Union>[<xref:str>, <xref:azure.ai.ml.entities.Environment>]
  - name: inputs
    description: Mapping of inputs data bindings used in the job.
    isRequired: true
    types:
    - <xref:dict>
  - name: outputs
    description: Mapping of outputs data bindings used in the job.
    isRequired: true
    types:
    - <xref:dict>
  - name: args
    description: Arguments for the job.
    isRequired: true
    types:
    - <xref:str>
methods:
- uid: azure.ai.ml.entities.SparkComponent.dump
  name: dump
  summary: Dump the component content into a file in yaml format.
  signature: 'dump(dest: str | PathLike | IO, **kwargs) -> None'
  parameters:
  - name: dest
    description: 'The destination to receive this component''s content.

      Must be either a path to a local file, or an already-open file stream.

      If dest is a file path, a new file will be created,

      and an exception is raised if the file exists.

      If dest is an open file, the file will be written to directly,

      and an exception will be raised if the file is not writable.'
    isRequired: true
    types:
    - <xref:Union>[<xref:PathLike>, <xref:str>, <xref:IO>[<xref:AnyStr>]]
attributes:
- uid: azure.ai.ml.entities.SparkComponent.base_path
  name: base_path
  summary: Base path of the resource.
  return:
    description: Base path of the resource
    types:
    - <xref:str>
- uid: azure.ai.ml.entities.SparkComponent.creation_context
  name: creation_context
  summary: Creation context.
  return:
    description: Creation metadata of the resource.
    types:
    - <xref:Optional>[<xref:azure.ai.ml.entities.SystemData>]
- uid: azure.ai.ml.entities.SparkComponent.display_name
  name: display_name
  summary: Display name of the component.
  return:
    description: Display name of the component.
    types:
    - <xref:str>
- uid: azure.ai.ml.entities.SparkComponent.entry
  name: entry
- uid: azure.ai.ml.entities.SparkComponent.environment
  name: environment
- uid: azure.ai.ml.entities.SparkComponent.id
  name: id
  summary: Resource ID.
  return:
    description: Global id of the resource, Azure Resource Manager ID
    types:
    - <xref:Optional>[<xref:str>]
- uid: azure.ai.ml.entities.SparkComponent.inputs
  name: inputs
  summary: Inputs of the component.
  return:
    description: Inputs of the component.
    types:
    - <xref:dict>
- uid: azure.ai.ml.entities.SparkComponent.is_deterministic
  name: is_deterministic
  summary: Whether the component is deterministic.
  return:
    description: Whether the component is deterministic
    types:
    - <xref:bool>
- uid: azure.ai.ml.entities.SparkComponent.outputs
  name: outputs
  summary: Outputs of the component.
  return:
    description: Outputs of the component.
    types:
    - <xref:dict>
- uid: azure.ai.ml.entities.SparkComponent.type
  name: type
  summary: Type of the component, default is 'command'.
  return:
    description: Type of the component.
    types:
    - <xref:str>
- uid: azure.ai.ml.entities.SparkComponent.version
  name: version
- uid: azure.ai.ml.entities.SparkComponent.CODE_ID_RE_PATTERN
  name: CODE_ID_RE_PATTERN
  signature: CODE_ID_RE_PATTERN = re.compile('\\/subscriptions\\/(?P<subscription>[\\w,-]+)\\/resourceGroups\\/(?P<resource_group>[\\w,-]+)\\/providers\\/Microsoft\\.MachineLearningServices\\/workspaces\\/(?P<workspace>[\\w,-]+)\\/codes\\/(?P<co)
